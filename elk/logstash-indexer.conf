input {
  redis {
     type => "access"
     add_field => {}
     batch_count => 10
     codec => "plain"
     data_type => "list"
     db => 0
     host => "127.0.0.1"
     key => "logstash-access"
     port => 6379
     #threads => 1
     #timeout => 5
  }

  redis {
     type => "stream"
     host => "127.0.0.1"
     db => "0"
     data_type => "list"
     key => "logstash-stream"
  }
}

filter {
  if [type] == "access" {
          grok {
              patterns_dir => "/opt/elk/logstash-2.3.4/conf/grok"
              match => [
                "message","%{ACCESS}"
               ]
              add_field =>["received_at","%{@timestamp}"]
              remove_field => ["message"]
          }
  }else if [type] == "stream" {
          grok {
              patterns_dir => "/opt/elk/logstash-2.3.4/conf/grok"
              match => [
                "message","%{STREAMTMP}"
               ]
              add_field =>["received_at","%{@timestamp}"]
              remove_field => ["message"]
          }

  }
  mutate {
        convert => ["snapoff","float"]
        convert => ["timedelay","float"]
        convert => ["request_time","float"]
  }

  #if "_grokparsefailure" in [tags] {
  #      drop { }
  #}
  date {
      match =>["timestamp",'ISO8601']
  }

}

output {
  stdout {codec => "rubydebug"}
  if [type] == "access" {
    elasticsearch {
        action => index            # string (optional), default: "index"
        index => "access-%{+YYYY.MM.dd}"
        document_type => "access"      
                                   # bind_port => ... # number (optional)
#       cluster => "elasticsearch" # string (optional) The name of your cluster if you set it on the Elasticsearch side. Useful for discovery.
        codec => "rubydebug"       # codec (optional), default: "plain"
#       embedded => false          # boolean (optional), default: false
        flush_size => 5000         # number (optional), default: 5000
        hosts => "localhost:9200"  # string (optional) This is only required if the normal multicast/cluster discovery stuff won't work in your environment.
        idle_flush_time => 1       # number (optional), default: 1
        manage_template => true    # boolean (optional), default: true
                                   # node_name => ... # string (optional)
#       port => 9200              # string (optional)
#       protocol => "http"        # string, one of ["node", "transport", "http"] (optional)
                                   # user => username # string
                                   # password => password # string
                                   # template => ... # a valid filesystem path (optional)
                                   # template_name => "logstash" # string (optional), default: "logstash"
        template_overwrite => true # boolean (optional), default: false
	#tempalte => "access-*"
        workers => 1               # number (optional), default: 1
   }
  }else if [type] == "stream" {
	elasticsearch {
        	index => "logstash-%{+YYYY.MM.dd}"
		hosts => "localhost:9200"
        	document_type => "stream"      
		#template => "/opt/elk/elasticsearch-2.3.4/config/templates"
		template_name => "stream"
        	template_overwrite => true
	}

   }
}
